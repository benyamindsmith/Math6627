---
title: "Towards A Clear Understanding Of Rural Internet: What Statistical Measures Can Be Used To Assess, Compare And Forecast Internet Speeds For Rural Canadian Communities?"
subtitle: "A Consulting Project for Math 6627 (1/3)"
author: "Benjamin Smith"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  toc: yes

---

# Introduction

(Quoted from the SCC website)

The Government of Canada has committed to helping 95% of Canadian households and businesses access high-speed internet at minimum speeds of 50 Mbps download and 10 Mbps upload (hereinafter referred to as the “Commitment”) by 2026, and 100% by 2030. According to the CRTC, currently 45.6% of rural community households have access to the Commitment based on what’s available to them via an Internet Service Provider (e.g. Shaw, Telus, etc.) in their region, rather than what a rural household actually realizes at home in terms of internet speeds. 

For this case study, the SCC would like to understand the state of internet connectivity in both rural and underserved Canadian communities using consumer-provided data. The SCC claims that by using data directly from the consumer, it is possible ot better understand connectivity in these communities as measured by the consumers in their own homes. 

Specifically, the following is desired:

1. A statistical analysis of the current realized and forecasted internet speeds (upload and download) for rural and undeserved communities in terms of progress towards the Commitment;

2. A comparative analysis of rural and underserved communities in terms of progress towards the Commitment; and

3. The identification of statistically reliable methods to assess and compare rural and underserved communities's realized internet access.For this study in particular, the identification of reliable and reproducible statistical methods to understand connectivity of rural and underserved Canadian communities is critical. 

# The Data

The data was made available by [Ookla]() and [Statistics Canada](). One of the first things to check regarding the data is to see if any missing data is present in the dataset. The visual below shows that most of the missing data is related to population center information. Namely data on population center id, type and class (PCUID, PCTYPE, PCLASS). 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(ggspatial)
library(plotly)
library(rnaturalearth)
library(sf)
library(scales)
library(reshape2)
#dt<- readr::read_csv("./ConsultingData/ookla-canada-speed-tiles.csv")
# Accomidating for mtor
setwd("/home/ben2908")
dt<- readr::read_csv("./ookla-canada-speed-tiles.csv")
```

```{r, fig.cap="Missing data present in dataset provied"}
naniar::vis_miss(dt ,warn_large_data = FALSE)+
  theme(axis.text.x=element_text(angle=90))
```

After removing the rows with missing data, the remaining sample is  1,252,560 rows, which is still usable for this analysis. 

# Analysis


## Rural and Urban Towns

```{r}
# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_d_time = mean(avg_d_kbps)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_d_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Download Speed 2019-2021")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")


# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_u_time = mean(avg_u_kbps)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_u_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Upload Speed 2019-2021")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")

```

## Correlation Between Upload, Download and Latency times

```{r}
dt %>% 
  dplyr::select(avg_d_kbps,avg_u_kbps, avg_lat_ms,tests,devices) %>% 
  cor() %>% 
  melt() %>% 
  ggplot(mapping=aes(x=Var2,y=Var1,fill=value))+
  geom_tile()+
  scale_fill_gradient()+
  geom_text(mapping=aes(label=scales::percent(value)))+
  theme(axis.title = element_blank())
```

## Current Realized And Forecasted Internet Speeds (Upload And Download)

Due to the large number of observations, approaching this dataset with standard visuals was not easy to do. In lieu of this the use of directed acyclic graphs (DAGs) is employed to understand the relationship between variables available and develop the model accordingly. 

```{r}
library(ggdag)

dagify(download_time~latency,
       download_time ~ conn_type,
       download_time ~tests,
       download_time~year,
       download_time~quarter,
       quarter~year,
       latency~ conn_type,
       latency~no_of_devices,
       year~quarter,
       labels=c("download_time"="Download/Upload Time",
                "latency" = "Latency",
                "conn_type"="Connection Type\n(Fixed,Mobile)",
                "no_of_devices"="No. of Devices",
                "tests"="No. of tests",
                "year"="Year\n(2019,2020,2021)",
                "quarter"="Quarter\n(Q1,Q2,Q3,Q4)")) %>% 
  tidy_dagitty() %>% 
  mutate(xend=c(10.5,9,10.5,9,10.5,9,10.5,10.5,10.5,NA),
         yend=c(0,0,0,0,0,-1.7,0,0,0,NA),
         x=ifelse(name=="download_time",10.5,
                  ifelse(name=="latency",9,
                         ifelse(name=="conn_type",9.5,
                                       ifelse(name=="tests",8.5,
                                              ifelse(name=="year",9,
                                                     ifelse(name=="quarter",10,
                                                            8)))))),
         y=ifelse(name=="download_time",0,
                  ifelse(name=="latency",0,
                         ifelse(name=="conn_type",1,
                                       ifelse(name=="tests",-1,
                                              ifelse(name=="year",-1.7,
                                                     ifelse(name=="quarter",-2,
                                                            0)))))),
         effectType=ifelse(name %in% c("download_time",
                "latency",
                "conn_type",
                "no_of_devices",
                "tests",
                "year",
                "quarter"),"Fixed","Random")) %>% 
  ggdag(text=FALSE,use_labels = "label")+
  ggtitle("DAG of relationship between Fixed Effects and Download/Upload Time")+
  theme_dag()
```

It is from this DAG that the following mixed model is constructed. 

$$Y = X\beta + Zb$$ 

Where $X$ is the design matrix for the fixed effects, $Z$ is the design matrix of the random effects and $\beta$ and $b$ are the  fixed and random effects vectors. The fixed and random effects are: 


| Fixed Effects   | Random Effect                        |
| --------------- | ------------------------------------ |
| No. of devices  |  Province                            |
| Connection Type |  Population Center Class             |
| No. of Tests    |  Province*Population Center Class    |
| Year            |                                      |
| Quarter         |                                      |
| Year*Quarter    |                                      |

After running this model in SAS note the following: 



```{r}
X_download<- model.matrix(avg_d_kbps~ devices + conn_type+ tests + year*quarter + PRNAME,data=dt %>% 
  dplyr::select(avg_d_kbps,PRNAME, devices, conn_type, tests, year,quarter))
```

```{r}
library(lme4)

fit_download_time <- lmer(avg_d_kbps~ devices + conn_type+ tests + year*quarter+(1|PRNAME)+(1|PCCLASS) +(1|PRNAME:PCCLASS), data= data.frame(dt %>% filter(!is.na(PCCLASS)),stringsAsFactors = T))
```
```{r}
summary(fit_download_time)
```
## Rural and Underserved communities in terms of progress towards the Commitment

```{r}
# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_d_time = mean(avg_d_kbps)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_d_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Download Speed 2019-2021")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")


# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_u_time = mean(avg_u_kbps)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_u_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Upload Speed 2019-2021")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")

```

```{r}
# Average number of devices per tile over time

dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,quadkey) %>% 
  summarize(avg_devices = mean(devices),
            avg_d_kbps=mean(avg_d_kbps)) %>% 
    mutate(Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
           popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER"))))
  ggplot()+
  geom_point(mapping=aes(x=avg_devices,y=avg_d_kbps,color=popcenter_class))+
  facet_wrap(~Province)
```


## The identification of statistically reliable methods to assess and compare rural and underserved communities's realized internet access.

* Test test test.

## Maps

```{r}
# Convert dataset to sf object
dtt<- dt %>% st_as_sf(wkt  = "geometry")
```

```{r}
world_map <- ne_countries(scale = "large", returnclass = 'sf')
canada_map <- world_map %>% filter(name =="Canada")
```


```{r}
# dtt %>%
#   ggplot()+
#   geom_sf()
```

```{r}
# Loading images
setwd("/home/ben2908")

df<- read_sf('ookla-canada-speed-tiles.shp')

df2<- read_sf('lpr_000b16a_e.shp')
```


```{r}
# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_d_kbps))+
#   ggtitle("Average Download Times in Canada")+
#   facet_wrap(year~quarter)
```

```{r}

# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_u_kbps))+
#   ggtitle("Average Upload Times in Canada")+
#   facet_wrap(year~quarter)
```


```{r}
# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_lat_ms))+
#   ggtitle("Average Latency Times in Canada")+
#   facet_wrap(year~quarter)
```



# References

# Code Appendix

## SAS Code

``` sas
/*Update File Path Accordingly*/
FILENAME REFFILE '.../ookla-canada-speed-tiles.csv';
PROC IMPORT DATAFILE=REFFILE
	DBMS=CSV
	OUT=DT;
	GETNAMES=YES;
RUN;

PROC CONTENTS DATA=DT; 
RUN;

/*Download Time*/
proc mixed data=DT method=reml covtest;
class PRNAME quarter year conn_type;
model avg_d_kbps= devices conn_type tests year quarter quarter*year;
random PRNAME/s;
run;


/*Upload Time*/
proc mixed data=DT method=reml covtest;
class PRNAME quarter year conn_type;
model avg_u_kbps= devices conn_type tests year quarter quarter*year;
random PRNAME/s;
run;
```
