---
title: "Towards A Clear Understanding Of Rural Internet: What Statistical Measures Can Be Used To Assess, Compare And Forecast Internet Speeds For Rural Canadian Communities?"
subtitle: "A Consulting Project for Math 6627 (1/3)"
author: "Benjamin Smith"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  toc: yes

---

# Introduction

(Quoted from the SCC website)

The Government of Canada has committed to helping 95% of Canadian households and businesses access high-speed internet at minimum speeds of 50 Mbps download and 10 Mbps upload (hereinafter referred to as the “Commitment”) by 2026, and 100% by 2030. According to the CRTC, currently 45.6% of rural community households have access to the Commitment based on what’s available to them via an Internet Service Provider (e.g. Shaw, Telus, etc.) in their region, rather than what a rural household actually realizes at home in terms of internet speeds. 

For this case study, the SCC would like to understand the state of internet connectivity in both rural and underserved Canadian communities using consumer-provided data. The SCC claims that by using data directly from the consumer, it is possible to better understand connectivity in these communities as measured by the consumers in their own homes. 

Specifically, the following is desired:

1. A statistical analysis of the current realized and forecasted internet speeds (upload and download) for rural and undeserved communities in terms of progress towards the Commitment;

2. A comparative analysis of rural and underserved communities in terms of progress towards the Commitment; and

3. The identification of statistically reliable methods to assess and compare rural and underserved communities's realized internet access.For this study in particular, the identification of reliable and reproducible statistical methods to understand connectivity of rural and underserved Canadian communities is critical. 

The following analysis aims to address the above in a practical and concise manner. 

# The Data

The data was made available by the [Statiscal Society of Canada](https://ssc.ca/en/case-study/towards-a-clear-understanding-rural-internet-what-statistical-measures-can-be-used-assess) with [Ookla](https://www.ookla.com) and [Statistics Canada](https://www.statcan.gc.ca/en/start). One of the first things to check regarding the data is to see if any missing data is present in the dataset. Figure 1 shows that most of the missing data is related to population center information. Namely data on population center id, type and class (PCUID, PCTYPE, PCLASS). 

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggthemes)
library(ggspatial)
library(plotly)
library(rnaturalearth)
library(sf)
library(scales)
library(reshape2)
#dt<- readr::read_csv("./ConsultingData/ookla-canada-speed-tiles.csv")
# Accomidating for mtor
setwd("/home/ben2908")
dt<- readr::read_csv("./ookla-canada-speed-tiles.csv")
```

```{r, fig.cap="Missing data present in dataset provied"}
naniar::vis_miss(dt ,warn_large_data = FALSE)+
  theme(axis.text.x=element_text(angle=90))
```

While it is possible to apply some treatment to the missing data, after removal, the remaining sample is  1,252,560 rows, which is still usable for this analysis. As such a filtered data set is used. 

# Analysis


## Rural and Urban Towns

Figures 2 and 3 show that on average, most provinces are keeping to the Commitment above and beyond the requirements provided for all communities. The provinces which appear to be experiencing challenges with this are the Northwest Territories, Nunavut and Yukon- all of whom have available data on small population centers^[According to Wikipedia there are only small population centers in the Canadian Territories as of 2016. Reference: https://en.wikipedia.org/wiki/List_of_population_centres_in_the_Canadian_Territories]. While this does offer a "birds eye view" a more accurate portrayal is to look at the proportion of tiles in population centers which are meeting the agreement  and which are not. Figures 4-9 outline such characteristics. In terms of small population centers, all provinces appear to be making progress in the Comittment with the exception to Nunavut 

```{r}
# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_d_time = mean(avg_d_kbps/1000)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_d_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Average Download Speed 2019-2021")+
  labs(y="Average Download Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")

```


```{r}
# Need to filter based on PCCLASS
dt %>% 
  filter(!is.na(PCCLASS)) %>% 
  group_by(PCCLASS,PRNAME,year,quarter) %>% 
  summarize(average_u_time = mean(avg_u_kbps/1000)) %>% 
  mutate(year_quarter=paste(year,quarter),
         Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
         popcenter_class = ifelse(PCCLASS==2, "Small (1000-29,999)",ifelse(PCCLASS==3, "Medium (30,000-99,999)",ifelse(PCCLASS==4,"Large (>100,000)","OTHER")))) %>% 
  ggplot(mapping=aes(x= year_quarter,y=average_u_time,color= popcenter_class,group= popcenter_class))+
  geom_point()+
  geom_line()+
  facet_wrap(~Province)+
  ggtitle("Average Upload Speed 2019-2021")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")

```

```{r}
# Small Provinces

smallProvs_Download<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Small (1000-29,999)") %>% 
                group_by(Province, year_quarter) %>% 
                count(d_status) 


smallProvs_Download<- do.call(rbind,
                     by(smallProvs_Download,smallProvs_Download["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

smallProvs_Download %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=d_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Small Population Centers Meeting the Commitment (Download Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
             
```

```{r}

smallProvs_Upload<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Small (1000-29,999)") %>% 
                group_by(Province, year_quarter) %>% 
                count(u_status) 


smallProvs_Upload<- do.call(rbind,
                     by(smallProvs_Upload,smallProvs_Upload["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

smallProvs_Upload %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=u_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Small Population Centers Meeting the Commitment (Upload Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
```

```{r}
# Medium 
medProvs_Download<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Medium (30,000-99,999)") %>% 
                group_by(Province, year_quarter) %>% 
                count(d_status) 


medProvs_Download<- do.call(rbind,
                     by(medProvs_Download,medProvs_Download["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

medProvs_Download %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=d_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Medium Population Centers Meeting the Commitment (Download Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
             
```

```{r}
# Medium 
medProvs_Upload<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Medium (30,000-99,999)") %>% 
                group_by(Province, year_quarter) %>% 
                count(u_status) 


medProvs_Upload<- do.call(rbind,
                     by(medProvs_Upload,medProvs_Upload["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

medProvs_Upload %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=u_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Medium Population Centers Meeting the Commitment (Upload Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
             
```

```{r}
# Large 
largeProvs_Download<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Large (>100,000)") %>% 
                group_by(Province, year_quarter) %>% 
                count(d_status) 


largeProvs_Download<- do.call(rbind,
                     by(largeProvs_Download,largeProvs_Download["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

largeProvs_Download %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=d_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Large Population Centers Meeting the Commitment (Download Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
```

```{r}
# Large 
largeProvs_Upload<- dt %>%
              mutate(year_quarter=paste(year,quarter),
                     Province= ifelse(grepl("\\/",PRNAME),PRNAME %>% str_extract('.*(?= \\/)'),PRNAME),
                      popcenter_class = ifelse(PCCLASS==2, 
                                               "Small (1000-29,999)",
                                               ifelse(PCCLASS==3, 
                                                      "Medium (30,000-99,999)",
                                                      ifelse(PCCLASS==4,"Large (>100,000)",
                                                             "OTHER"))),
                      d_status=ifelse((avg_d_kbps/1000)<50,"Below Commitment","Meeting Commitment"),
                      u_status=ifelse((avg_u_kbps/1000)<10,"Below Commitment","Meeting Commitment")) %>% 
                filter(!is.na(PCCLASS),popcenter_class=="Large (>100,000)") %>% 
                group_by(Province, year_quarter) %>% 
                count(d_status) 


largeProvs_Upload<- do.call(rbind,
                     by(largeProvs_Upload,largeProvs_Upload["Province"],tibble) %>% 
                     lapply(function(x) do.call(rbind,by(x,x["year_quarter"],tibble) %>% 
                                                  lapply(function(y) y %>% mutate(prop = y$n/sum(y$n)))))
)

largeProvs_Upload %>% 
  ggplot(mapping=aes(x=year_quarter,y=prop,fill=d_status))+
  geom_bar(stat="identity")+
  facet_wrap(~Province)+
  ggtitle("Proportion of Large Population Centers Meeting the Commitment (Upload Speed)")+
  labs(y="Average Upload Speed (mbps)")+
  scale_color_discrete(guide = guide_legend(reverse=TRUE))+
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.title = element_blank(),
        legend.title=element_blank(),
        legend.position = "bottom")
```

## Correlation Between Upload, Download and Latency times

```{r}
dt %>% 
  dplyr::select(avg_d_kbps,avg_u_kbps, avg_lat_ms,tests,devices) %>% 
  cor() %>% 
  melt() %>% 
  ggplot(mapping=aes(x=Var2,y=Var1,fill=value))+
  geom_tile()+
  scale_fill_gradient()+
  geom_text(mapping=aes(label=scales::percent(value)))+
  theme(axis.title = element_blank())
```

## Current Realized And Forecasted Internet Speeds (Upload And Download)

Due to the large number of observations, approaching this dataset with standard visuals was not easy to do. In lieu of this the use of directed acyclic graphs (DAGs) is employed to understand the relationship between variables available and develop the model accordingly. 

```{r}
library(ggdag)

dagify(download_time~latency,
       download_time ~ conn_type,
       download_time ~tests,
       download_time~year,
       download_time~quarter,
       quarter~year,
       latency~ conn_type,
       latency~no_of_devices,
       year~quarter,
       labels=c("download_time"="Download/Upload Time",
                "latency" = "Latency",
                "conn_type"="Connection Type\n(Fixed,Mobile)",
                "no_of_devices"="No. of Devices",
                "tests"="No. of tests",
                "year"="Year\n(2019,2020,2021)",
                "quarter"="Quarter\n(Q1,Q2,Q3,Q4)")) %>% 
  tidy_dagitty() %>% 
  mutate(xend=c(10.5,9,10.5,9,10.5,9,10.5,10.5,10.5,NA),
         yend=c(0,0,0,0,0,-1.7,0,0,0,NA),
         x=ifelse(name=="download_time",10.5,
                  ifelse(name=="latency",9,
                         ifelse(name=="conn_type",9.5,
                                       ifelse(name=="tests",8.5,
                                              ifelse(name=="year",9,
                                                     ifelse(name=="quarter",10,
                                                            8)))))),
         y=ifelse(name=="download_time",0,
                  ifelse(name=="latency",0,
                         ifelse(name=="conn_type",1,
                                       ifelse(name=="tests",-1,
                                              ifelse(name=="year",-1.7,
                                                     ifelse(name=="quarter",-2,
                                                            0)))))),
         effectType=ifelse(name %in% c("download_time",
                "latency",
                "conn_type",
                "no_of_devices",
                "tests",
                "year",
                "quarter"),"Fixed","Random")) %>% 
  ggdag(text=FALSE,use_labels = "label")+
  ggtitle("DAG of relationship between Fixed Effects and Download/Upload Time")+
  theme_dag()
```

It is from this DAG that the following mixed model is constructed. 

$$Y = X\beta + Zb$$ 

Where $X$ is the design matrix for the fixed effects, $Z$ is the design matrix of the random effects and $\beta$ and $b$ are the  fixed and random effects vectors. The fixed and random effects are: 


| Fixed Effects   | Random Effect                        |
| --------------- | ------------------------------------ |
| No. of devices  |  Province                            |
| Connection Type |  Population Center Class             |
| No. of Tests    |  Province*Population Center Class    |
| Year            |                                      |
| Quarter         |                                      |
| Year*Quarter    |                                      |

After running this model in SAS note the following: 



```{r}
X_download<- model.matrix(avg_d_kbps~ devices + conn_type+ tests + year*quarter + PRNAME,data=dt %>% 
  dplyr::select(avg_d_kbps,PRNAME, devices, conn_type, tests, year,quarter))
```

```{r}
library(lme4)

fit_download_time <- lmer(avg_d_kbps~ devices + conn_type+ tests + year*quarter+(1|PRNAME)+(1|PCCLASS) +(1|PRNAME:PCCLASS), data= data.frame(dt %>% filter(!is.na(PCCLASS)),stringsAsFactors = T))
```
```{r}
summary(fit_download_time)
```
## Rural and Underserved communities in terms of progress towards the Commitment


## The identification of statistically reliable methods to assess and compare rural and underserved communities's realized internet access.

* Test test test.

## Maps

```{r}
# Convert dataset to sf object
dtt<- dt %>% st_as_sf(wkt  = "geometry")
```

```{r}
world_map <- ne_countries(scale = "large", returnclass = 'sf')
canada_map <- world_map %>% filter(name =="Canada")
```


```{r}
# dtt %>%
#   ggplot()+
#   geom_sf()
```

```{r}
# Loading images
setwd("/home/ben2908")

df<- read_sf('ookla-canada-speed-tiles.shp')

df2<- read_sf('lpr_000b16a_e.shp')
```


```{r}
# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_d_kbps))+
#   ggtitle("Average Download Times in Canada")+
#   facet_wrap(year~quarter)
```

```{r}

# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_u_kbps))+
#   ggtitle("Average Upload Times in Canada")+
#   facet_wrap(year~quarter)
```


```{r}
# ggplot()+
#   geom_sf(data=df2)+
#   geom_sf(data=df,mapping=aes(color=avg_lat_ms))+
#   ggtitle("Average Latency Times in Canada")+
#   facet_wrap(year~quarter)
```



# References

# Code Appendix

## SAS Code

``` sas
/*Update File Path Accordingly*/
FILENAME REFFILE '.../ookla-canada-speed-tiles.csv';
PROC IMPORT DATAFILE=REFFILE
	DBMS=CSV
	OUT=DT;
	GETNAMES=YES;
RUN;

PROC CONTENTS DATA=DT; 
RUN;

/*Download Time*/
proc mixed data=DT method=reml covtest;
class PRNAME quarter year conn_type;
model avg_d_kbps= devices conn_type tests year quarter quarter*year;
random PRNAME/s;
run;


/*Upload Time*/
proc mixed data=DT method=reml covtest;
class PRNAME quarter year conn_type;
model avg_u_kbps= devices conn_type tests year quarter quarter*year;
random PRNAME/s;
run;
```
