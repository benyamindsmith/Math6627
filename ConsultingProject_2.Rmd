---
title: "What Predicts The Popularity Of Ted Talks?"
subtitle: "A Consulting Project for Math 6627 (2/3)"
author: "Benjamin Smith"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: 
    includes: 
      in_header: "ConsultingProject1.tex"
    toc: true
    

---
\listoffigures
\listoftables
\newpage

# Introduction


(Quoted from the SSC website)

[TED](https://www.ted.com) spreads ideas, primarily via short talks that can be accessed on the internet. As noted on its website, TED was initiated in 1984 as a conference where technology, entertainment, and design ideas were shared. At present, TED Talks cover topics ranging from science to business to global issues.


The following analysis focuses on the use of inferential techniques to analyze the data. The questions addressed in this analysis are: 

* What characteristics of TED Talks predict their popularity? 

* What different ways could the popularity of TED Talks be measured? 

* Do the characteristics that predict popularity change over time? 

* Do the characteristics that predict popularity differ based on the theme of the TED Talks? (Mixed Model!!)

# The Data

The data was made available by [Kaggle](https://www.kaggle.com/). Figure 1 shows that there very little data missing in this data set. As such there is no treatment applied to the data and it is used as is.

```{r echo=FALSE, message=FALSE, warning=FALSE,fig.cap="There is little to no missing data in this dataset"}
library(tidyverse)
library(stringr)
library(stringi)
library(glmnet)
library(lme4)
library(jsonlite)
library(yaml)
library(tidyr)
dt<- readr::read_csv('./ted_main.csv')

# No missing data
naniar::vis_miss(dt)+
  theme(axis.text.x = element_text(angle = 90))
```


The present structure of the data has nested .json fields and they needs to be unnested and expanded. 

```{r}

ratingsDf<- dt$ratings %>% 
            lapply(function(x) read_yaml(text=x)) %>% 
            lapply(function(x) do.call(rbind,x))

# Using a for loop because vectorizing is hard. Don't make fun of me

for(i in 1:length(ratingsDf)){
  
  ratingsDf[[i]]<- ratingsDf[[i]] %>% 
                   as.data.frame.matrix() %>% 
                   transmute(ratingID= id,
                             ratingTag = name,
                             count=count,
                             url= rep(dt$url[i],length(ratingsDf[[i]][,1])))
  
}

ratingsDf<-do.call(rbind,ratingsDf) %>% unnest()

# Manually editing JSON Files to be read into R
# The titles may differ as such
setwd("Proj2JsonFiles")
for(i in 1:length(dt$related_talks)){
 
  write(dt$related_talks[i] %>%
          str_remove_all("(?<=\\w)\\'(?=\\w)") %>%
          str_remove_all("’") %>%  
          str_remove_all("\\\\'") %>% 
          str_replace("é","e") %>% 
          stri_trans_general("latin-ascii"),paste0(i,'.json'))
}

relatedTalksJSON<- list()

for(i in 1:length(dt$related_talks)){
  tryCatch(
    { relatedTalksJSON[[i]]<- read_yaml(paste0(i,'.json')) },
    error = function(e){
      tryCatch(
        {
          relatedTalksJSON[[i]]<-read_yaml(text=dt$related_talks[i] %>% str_remove_all("\\'"))
        },
        error = function(f) {
           relatedTalksJSON[[i]]<-read_yaml(text=dt$related_talks[i] %>% str_remove_all('\\"') %>% str_remove_all("\\\\'") %>% stri_trans_general("latin-ascii")) 
        },
        finally=i
               )
      }
      ,
    finally=i
  )
}


for(i in 1:length(relatedTalksJSON)){
  
    relatedTalksJSON[[i]]<- relatedTalksJSON[[i]] %>% lapply(function(y) as.data.frame(y) %>% mutate(url=dt$url[i]))
      
  
}

relatedTalksJSONDf<-list()
for (i in 1:length(relatedTalksJSON)){
  relatedTalksJSONDf[[i]]<-do.call(rbind,relatedTalksJSON[i])
}

relatedTalksJSONDf <- relatedTalksJSONDf %>% lapply(function(x) t(x))
relatedTalksJSONDf<-do.call(rbind,do.call(rbind,relatedTalksJSONDf)) %>% 
                    transmute(related_talks_id=id,
                              related_talks_hero=hero,
                              related_talks_speaker=speaker,
                              related_talks_title=title,
                              related_talks_duration=duration,
                              related_talks_slug = slug,
                              related_talks_view_count = viewed_count,
                              url=url)


tagsDf <- dt$tags %>% 
  lapply(function(x) read_yaml(text=x) %>% as_tibble()) 

for(i in 1:length(tagsDf)){
  tagsDf[[i]]<- tagsDf[[i]] %>% 
                   transmute(tagValue=value,
                             url = rep(dt$url[i],length(tagsDf [[i]][,1])))
}

tagsDf<- do.call(rbind,tagsDf)
```


```{r}
# Need to fix dates
fullyJoinedDf<- ratingsDf %>%
                left_join(tagsDf,by= "url") %>% 
                left_join(dt, by="url") %>% 
                select(!c(description,tags,related_talks,ratings)) %>% 
                mutate(
                       film_date = lubridate::as_datetime(film_date),
                       published_date=lubridate::as_datetime(published_date))
              
```


```{r}
# Working dataframe
dtt<-fullyJoinedDf %>%
      select(!ratingID) %>% 
      pivot_wider(names_from = ratingTag, 
                  values_from = count,
                  names_prefix = "rating_") %>% 
      pivot_wider(names_from=tagValue,
                  values_from=tagValue,
                  names_prefix = "tag_") %>% 
      mutate(across(names(dtt)[grepl("tag_",names(dtt))],~ ifelse(!is.na(.x),1,0)))
```


# Analysis

## Characteristics of TED Talks predict popularity

This can be done by using LASSO regression

```{r}
y <- dtt$views
X <- data.matrix(dtt[,-which(names(dtt) %in% c("views"))])
```

```{r}
#perform k-fold cross-validation to find optimal lambda value
cv_model_views <- cv.glmnet(X, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda<- cv_model_views$lambda.min

#produce plot of test MSE by lambda value
plot(cv_model_views, main =expression("MSE vs "*lambda[views]*""))
```

```{r}
best_model_views <- glmnet(X, y, alpha = 1, lambda = best_lambda)

as.matrix(coef(best_model_views),rownames) %>% 
  as.data.frame.matrix() %>% 
  filter(s0!=0) %>% 
  knitr::kable(caption="Sparse Estimates for Ted Talk Popularity (in terms of Views)")
```

## Different ways could the popularity of TED Talks be measured

From simple inspection of the data the two possible ways that the popularity of a Ted Talk can be measured would be in terms of number of views and rating. Since we explored views in the previous section, in this section we will focus on rating and comments. 

### Rating 

From the data set it was determined that there are 14 unique rating tags for each TED talk. 

```{r}
tibble(`Rating Tag` = unique(fullyJoinedDf$ratingTag),
       Classification = c("Good","Good","Good",
                          "Good","Bad","Bad",
                          "Good","Good","Bad",
                          "Good","Good","Ambiguos",
                          "Bad","Bad")) %>%
  knitr::kable(caption="Unique Rating Tags accross all Ted Talks")
```

```{r}
# Including Good/Bad Ratio
dtt<-dtt %>% 
  rowwise() %>% 
  mutate(`Good/Bad Ratio` = sum(rating_Funny,
                                rating_Beautiful,
                                rating_Ingenious,
                                rating_Courageous,
                                rating_Informative,
                                rating_Fascinating,
                                rating_Persuasive,
                                `rating_Jaw-dropping`)/sum(rating_Longwinded,
                                                           rating_Confusing,
                                                           rating_Unconvincing,
                                                           rating_Obnoxious,
                                                           rating_Inspiring))
```


```{r message=TRUE, warning=FALSE}
dtt %>%
group_by(`Good/Bad Ratio`) %>% 
arrange(-desc(`Good/Bad Ratio`),.by_group = T) %>%
select(name,`Good/Bad Ratio`,views,comments,published_date) %>% 
filter(`Good/Bad Ratio` < 0.6083570) %>% 
knitr::kable(caption="Top 10 Worst Ted Talks")
```

```{r}
dtt %>%
group_by(`Good/Bad Ratio`) %>% 
arrange(desc(`Good/Bad Ratio`)) %>%
select(name,`Good/Bad Ratio`,views,comments,published_date) %>% 
filter(`Good/Bad Ratio` >= 18.714285) %>% 
knitr::kable(caption="Top 10 Best Ted Talks")  
```

### Comments

If we want to look at it in terms of engagement, we can view it in terms of comments



```{r}
# Comments

y <- dtt$comments
X <- data.matrix(dtt[,-which(names(dtt) %in% c("comments"))])
```

```{r}
#perform k-fold cross-validation to find optimal lambda value
cv_model_comments <- cv.glmnet(X, y, alpha = 1)
#find optimal lambda value that minimizes test MSE
best_lambda<- cv_model_comments$lambda.min

#produce plot of test MSE by lambda value
plot(cv_model_comments, main =expression("MSE vs "*lambda[comments]*""))
```

```{r}
best_model_comments <- glmnet(X, y, alpha = 1, lambda = best_lambda)

as.matrix(coef(best_model_comments),rownames) %>% 
  as.data.frame.matrix() %>% 
  filter(s0!=0) %>% 
  knitr::kable(caption="Sparse Estimates for Ted Talk Popularity (in terms of comments)")
```

## Characteristics predicting popularity over time

```{r}
fullyJoinedDf %>% 
  ggplot()+
  geom_point(mapping=aes(x=published_date,y=count,color=tagValue))+
  facet_wrap(~ratingTag)
```


